{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d700c27",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cabfa3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f39ac",
   "metadata": {},
   "source": [
    "Mathmatical definitions<br>\n",
    "$z^{(i)} = W^T.x^{(i)} + b$<br>\n",
    "$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})$<br>\n",
    "$sigmoid(z) = \\displaystyle\\frac{1}{1 + e^{-z}}$<br>\n",
    "$L(a^{(i)}, y^{(i)}) = -y^{(i)}\\log{a^{(i)}} - (1 - y^{(i)})\\log{(1 - a^{(i)})}$ <br>\n",
    "Cost function is the average sum over losses<br>\n",
    "$J = \\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=0}^{m}L(a^{(i)}, y^{(i)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950f76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8538ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(a_i, y_i):\n",
    "    return -y_i * np.log(a_i) - (1 - y_i) * np.log(1 - a_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a95d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575da248",
   "metadata": {},
   "source": [
    "## Propagate\n",
    "Now we do forward and backward propagations;\n",
    "Function below calculates the cost and gradients\n",
    "\n",
    "$\\displaystyle\\frac{\\partial{J}}{\\partial{w_{j}}} = \\frac{1}{m}\\sum_{i=1}^{m}(a^{(i)} - y^{(i)})x^{(i)}$ <br>\n",
    "$\\displaystyle\\frac{\\partial{J}}{\\partial{b}} = \\frac{1}{m}\\sum_{i=1}^{m}(a^{(i)} - y^{(i)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b730729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    n, m = X.shape\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    cost = np.sum(-1 * np.dot(Y, np.log(A).T) - np.dot(1 - Y, np.log(1 - A).T)) / m\n",
    "    \n",
    "    dz = A - Y\n",
    "    dw = 1/m * np.dot(X, dz.T)\n",
    "    db = np.sum(A - Y, axis=1) / m\n",
    "    \n",
    "    grads = dict(dw=dw, db=db)\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c23833b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dw': array([[ 0.25071532],\n",
       "         [-0.06604096]]),\n",
       "  'db': array([-0.12500405])},\n",
       " 0.15900537707692405)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w =  np.array([[1.], [2]])\n",
    "b = 1.5\n",
    "X = np.array([[1., -2., -1.], [3., 0.5, -3.2]])\n",
    "Y = np.array([[1, 1, 0]])\n",
    "propagate(w, b, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd1c95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, verbos=False):\n",
    "    costs = []\n",
    "    w = deepcopy(w)\n",
    "    b = deepcopy(b)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            if verbos: print(f'#{i + 1:{int(np.log10(num_iterations) + 1)}} cost is {cost}')\n",
    "            \n",
    "        params = dict(w=w, b=b)\n",
    "        grads = dict(dw=dw, db=db)\n",
    "        \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39e702ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  100 cost is 0.10579008649578009\n",
      "#  200 cost is 0.07702879258174412\n",
      "#  300 cost is 0.05989615811520176\n",
      "#  400 cost is 0.048764761454255595\n",
      "#  500 cost is 0.041042925381041144\n",
      "#  600 cost is 0.03541201128669937\n",
      "#  700 cost is 0.03114306413600132\n",
      "#  800 cost is 0.027805003553200393\n",
      "#  900 cost is 0.025128502865697035\n",
      "# 1000 cost is 0.022937505237866238\n",
      "# 1100 cost is 0.02111249872740779\n",
      "# 1200 cost is 0.019569730959083608\n",
      "# 1300 cost is 0.01824889259353497\n",
      "# 1400 cost is 0.01710552576566551\n",
      "# 1500 cost is 0.016106182511363983\n",
      "# 1600 cost is 0.015225243722652368\n",
      "# 1700 cost is 0.014442773681102618\n",
      "# 1800 cost is 0.013743039105931646\n",
      "# 1900 cost is 0.013113465559625255\n",
      "# 2000 cost is 0.012543888305947416\n",
      "# 2100 cost is 0.012026005491800348\n",
      "# 2200 cost is 0.011552972934424715\n",
      "# 2300 cost is 0.011119099688773199\n",
      "# 2400 cost is 0.01071961644175916\n",
      "# 2500 cost is 0.010350497272881268\n",
      "# 2600 cost is 0.010008321025241225\n",
      "# 2700 cost is 0.009690162426027112\n",
      "# 2800 cost is 0.009393505795626115\n",
      "# 2900 cost is 0.009116176082613024\n",
      "# 3000 cost is 0.008856283313575464\n",
      "# 3100 cost is 0.008612177521027262\n",
      "# 3200 cost is 0.008382411922836416\n",
      "# 3300 cost is 0.008165712649729056\n",
      "# 3400 cost is 0.007960953706568257\n",
      "# 3500 cost is 0.0077671361452698\n",
      "# 3600 cost is 0.007583370648460931\n",
      "# 3700 cost is 0.00740886289191504\n",
      "# 3800 cost is 0.007242901183760653\n",
      "# 3900 cost is 0.007084845979188689\n",
      "# 4000 cost is 0.006934120947980863\n",
      "# 4100 cost is 0.006790205333918682\n",
      "# 4200 cost is 0.006652627393922411\n",
      "# 4300 cost is 0.006520958743554311\n",
      "# 4400 cost is 0.006394809466531728\n",
      "# 4500 cost is 0.006273823870807156\n",
      "# 4600 cost is 0.006157676793909877\n",
      "# 4700 cost is 0.006046070376575178\n",
      "# 4800 cost is 0.005938731237015319\n",
      "# 4900 cost is 0.005835407989095268\n",
      "# 5000 cost is 0.005735869056654492\n",
      "# 5100 cost is 0.005639900743628593\n",
      "# 5200 cost is 0.005547305525770706\n",
      "# 5300 cost is 0.005457900534888854\n",
      "# 5400 cost is 0.005371516210785343\n",
      "# 5500 cost is 0.005287995099668089\n",
      "# 5600 cost is 0.005207190780811979\n",
      "# 5700 cost is 0.0051289669057900675\n",
      "# 5800 cost is 0.005053196336742515\n",
      "# 5900 cost is 0.004979760371976573\n",
      "# 6000 cost is 0.004908548048742584\n",
      "# 6100 cost is 0.004839455514357914\n",
      "# 6200 cost is 0.004772385457980925\n",
      "# 6300 cost is 0.00470724659631748\n",
      "# 6400 cost is 0.004643953207371059\n",
      "# 6500 cost is 0.004582424707075879\n",
      "# 6600 cost is 0.0045225852642745805\n",
      "# 6700 cost is 0.0044643634500399635\n",
      "# 6800 cost is 0.004407691917813284\n",
      "# 6900 cost is 0.00435250711123865\n",
      "# 7000 cost is 0.004298748996925954\n",
      "# 7100 cost is 0.0042463608196922275\n",
      "# 7200 cost is 0.0041952888780968775\n",
      "# 7300 cost is 0.004145482318328809\n",
      "# 7400 cost is 0.0040968929447132525\n",
      "# 7500 cost is 0.004049475045288525\n",
      "# 7600 cost is 0.0040031852310678726\n",
      "# 7700 cost is 0.003957982287744922\n",
      "# 7800 cost is 0.0039138270387272115\n",
      "# 7900 cost is 0.003870682218498046\n",
      "# 8000 cost is 0.003828512355402658\n",
      "# 8100 cost is 0.0037872836630478903\n",
      "# 8200 cost is 0.0037469639395820453\n",
      "# 8300 cost is 0.003707522474190274\n",
      "# 8400 cost is 0.003668929960209337\n",
      "# 8500 cost is 0.0036311584143142004\n",
      "# 8600 cost is 0.003594181101288027\n",
      "# 8700 cost is 0.0035579724639244214\n",
      "# 8800 cost is 0.0035225080576585916\n",
      "# 8900 cost is 0.003487764489553239\n",
      "# 9000 cost is 0.0034537193613065546\n",
      "# 9100 cost is 0.0034203512159695377\n",
      "# 9200 cost is 0.0033876394880957583\n",
      "# 9300 cost is 0.003355564457064535\n",
      "# 9400 cost is 0.00332410720334226\n",
      "# 9500 cost is 0.003293249567468287\n",
      "# 9600 cost is 0.003262974111567158\n",
      "# 9700 cost is 0.0032332640832042343\n",
      "# 9800 cost is 0.0032041033814223063\n",
      "# 9900 cost is 0.003175476524802263\n",
      "#10000 cost is 0.0031473686214096657\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs  = optimize(w, b, X, Y, 10000, verbos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f11310",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Now using predicted outcome we classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1d1e357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X, threshold=0.5):\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    A[A > threshold] = 1\n",
    "    A[A <= threshold] = 0\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb757c",
   "metadata": {},
   "source": [
    "## Merging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "72c95e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, Y_train, X_test, Y_test, num_iterations=1000, learning_rate=0.001, verbos=False):\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "    \n",
    "    params, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate)\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    \n",
    "    dw = grads['dw']\n",
    "    db = grads['db']\n",
    "    \n",
    "    y_train_pred = predict(w, b, X_train)\n",
    "    y_test_pred = predict(w, b, X_test)\n",
    "    \n",
    "    if verbos:\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_train_pred - Y_train)) * 100))\n",
    "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_test_pred - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": y_test_pred, \n",
    "         \"Y_prediction_train\" : y_train_pred, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "15989b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 100.0 %\n",
      "test accuracy: 100.0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'costs': [0.5847310319119523,\n",
       "  0.5038389287421158,\n",
       "  0.4426825284032568,\n",
       "  0.3951469007164264,\n",
       "  0.3572054105364358,\n",
       "  0.3261973269679616,\n",
       "  0.3003347778596492,\n",
       "  0.27838904591293473,\n",
       "  0.25949486835947394,\n",
       "  0.24302800501521693],\n",
       " 'Y_prediction_test': array([[1., 1., 0.]]),\n",
       " 'Y_prediction_train': array([[1., 1., 0.]]),\n",
       " 'w': array([[-0.10282038],\n",
       "        [ 0.61271228]]),\n",
       " 'b': array([0.13516195]),\n",
       " 'learning_rate': 0.001,\n",
       " 'num_iterations': 1000}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(X, Y, X, Y, verbos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb69072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
