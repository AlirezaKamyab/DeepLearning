{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ef4287",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48caba8",
   "metadata": {},
   "source": [
    "## Notations and demonstrations\n",
    "- $m$ is denoted as the number of training examples\n",
    "- $n$ is denoted as the number of the features\n",
    "- $X$ is a matrix that each column is a training example and each row is a feature <br>\n",
    "$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "    \\displaystyle\n",
    "    x^{(1)}_{1} & x^{(2)}_{1} & \\dots & x^{(m)}_{1} \\\\\n",
    "    x^{(1)}_{2} & x^{(2)}_{2} & \\dots & x^{(m)}_{2} \\\\\n",
    "    & \\vdots & \\vdots & \\\\\n",
    "    x^{(1)}_{n} & x^{(2)}_{n} & \\dots & x^{(m)}_{n} \\\\\n",
    "\\end{bmatrix}_{n_x \\times m}\n",
    "$\n",
    "- $y$ is a vector denoted as the labels <br>\n",
    "$\n",
    "y = \n",
    "\\begin{bmatrix}\n",
    "    y_1 & y_2 & \\dots & y_m\n",
    "\\end{bmatrix}\n",
    "$\n",
    "- $w$ is a vector of weights <br>\n",
    "$\n",
    "w = \n",
    "\\begin{bmatrix}\n",
    "\\displaystyle\n",
    "    w_1\\\\\n",
    "    w_2\\\\\n",
    "    \\vdots\\\\\n",
    "    w_n\n",
    "\\end{bmatrix}\n",
    "$\n",
    "<br> <br>\n",
    "Neural networks might have multiple layers; each layers contains multiple perceptron and each themselves could be logistic function or ...; so for each we need different vector of weights that could be obtained via stacking each function's weights in a matrix;\n",
    "<br>\n",
    "- $W^{[1]}$ is a matrix for the first layer of the neural network; for example, if the first layer contains 4 logistic functions we have<br>\n",
    "$\n",
    "W^{[1]} =\n",
    "\\displaystyle\n",
    "\\begin{bmatrix}\n",
    "    \\dots & w_1^{[1]T} & \\dots\\\\\n",
    "    \\dots & w_2^{[1]T} & \\dots\\\\\n",
    "    \\dots & w_3^{[1]T} & \\dots\\\\\n",
    "    \\dots & w_4^{[1]T} & \\dots\\\\\n",
    "\\end{bmatrix}_{4, n}\n",
    "$\n",
    "<br><br>\n",
    "Since we have multiple functions in each layer, we need multiple intercepts.\n",
    "- $b$ is vector of intercepts; If we have 4 logistic function in the first layer, it would be like below <br>\n",
    "$\n",
    "b^{[1]} = \n",
    "\\displaystyle\n",
    "\\begin{bmatrix}\n",
    "    b_1^{[1]}\\\\\n",
    "    b_2^{[1]}\\\\\n",
    "    b_3^{[1]}\\\\\n",
    "    b_4^{[1]}\\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "<br><br>\n",
    "For calculating $Z$ we have\n",
    "$$\n",
    "Z^{[1]} = \n",
    "\\begin{bmatrix}\n",
    "    \\dots & w_1^{[1]T} & \\dots\\\\\n",
    "    \\dots & w_2^{[1]T} & \\dots\\\\\n",
    "    \\dots & w_3^{[1]T} & \\dots\\\\\n",
    "    \\dots & w_4^{[1]T} & \\dots\\\\\n",
    "\\end{bmatrix}_{4, n}\n",
    "\\begin{bmatrix}\n",
    "    \\displaystyle\n",
    "    x^{(1)} & x^{(2)} & \\dots & x^{(m)}\n",
    "\\end{bmatrix}_{n_x \\times m} + \n",
    "\\begin{bmatrix}\n",
    "    b_1^{[1]}\\\\\n",
    "    b_2^{[1]}\\\\\n",
    "    b_3^{[1]}\\\\\n",
    "    b_4^{[1]}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "The result will be\n",
    "$$\n",
    "Z^{[1]} = \n",
    "\\begin{bmatrix}\n",
    "    \\displaystyle\n",
    "    W_1^{[1]T}.x^{(1)} + b_1^{[1]}\\\\\n",
    "    W_2^{[1]T}.x^{(2)} + b_2^{[1]}\\\\\n",
    "    W_3^{[1]T}.x^{(3)} + b_3^{[1]}\\\\\n",
    "    W_4^{[1]T}.x^{(4)} + b_4^{[1]}\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    \\displaystyle\n",
    "    Z_1^{[1]}\\\\\n",
    "    Z_2^{[1]}\\\\\n",
    "    Z_3^{[1]}\\\\\n",
    "    Z_4^{[1]}\\\\\n",
    "\\end{bmatrix}_{4, m}\n",
    "$$\n",
    "\n",
    "Applying the activation function for the first layer containing 4 perceptrons we have\n",
    "$$\n",
    "a^{[1]} = \n",
    "\\begin{bmatrix}\n",
    "    \\displaystyle\n",
    "    a_1^{[1]}\\\\\n",
    "    a_2^{[1]}\\\\\n",
    "    a_3^{[1]}\\\\\n",
    "    a_4^{[1]}\\\\\n",
    "\\end{bmatrix}\n",
    "= G(Z^{[1]})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d553824",
   "metadata": {},
   "source": [
    "## Activation functions\n",
    "- Sigmoid\n",
    "$$\n",
    "    \\begin{equation}\n",
    "        a = g(z) = \\displaystyle\\frac{1}{1 + e^{-z}} \\\\\n",
    "    \\end{equation}\n",
    "$$\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg\" width=\"300px\" height=\"300px\"/>\n",
    "\n",
    "    - Derivative\n",
    "    $$\n",
    "        \\begin{equation}\n",
    "            g'(z) = \\frac{dg(z)}{dz} = \\frac{1}{1 + e^{-z}}(1 - \\frac{1}{1 + e^{-z}}) \\\\ \n",
    "            g'(z) = g(z)(1 - g(z)) = a(1 - a)\n",
    "        \\end{equation}\n",
    "    $$\n",
    "    Calculations :\n",
    "    $$\n",
    "        \\begin{equation}\n",
    "            \\frac{d}{dz}g(z) = \\frac{0 - (-e^{-z})}{(1 + e^{-z})^2} = \\frac{e^{-z}}{(1 + e^{-z})^2} = \\\\\n",
    "                \\frac{e^{-z} + 1 - 1}{1 + e^{-z}} \\times \\frac{1}{1 + e^{-z}} = \\\\\n",
    "                (1 - \\frac{1}{1 + e^{-z}})\\frac{1}{1+e^{-z}}\n",
    "        \\end{equation}\n",
    "    $$\n",
    "    <br><br>\n",
    "\n",
    "- tanh\n",
    "$$\n",
    "    \\begin{equation}\n",
    "        a = g(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\n",
    "    \\end{equation}\n",
    "$$\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/76/Sinh_cosh_tanh.svg\" width=\"300px\" height=\"300px\"/>\n",
    "\n",
    "    - Derivative\n",
    "    $$\n",
    "        \\begin{equation}\n",
    "        g'(z) = \\frac{d}{dz}tanh(z) = 1 - (tanh(z))^2\\\\\n",
    "        g'(z) = 1 - a^2\n",
    "        \\end{equation}\n",
    "    $$\n",
    "    Calculations:\n",
    "    $$\n",
    "        \\begin{equation}\n",
    "            \\frac{d}{dz} tanh(z) = \\frac{(e^z+e^{-z}) - (e^z-e^{-z})}{(e^z+e^{-z})^2} = \\\\\n",
    "            1 - \\frac{(e^z-e^{-z})}{e^z+e^{-z}} = 1 - (tanh(z))^2\n",
    "        \\end{equation}\n",
    "    $$\n",
    "\n",
    "<br><br>\n",
    "- ReLU\n",
    "$$\n",
    "    a = max(0, z)\n",
    "$$\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/42/ReLU_and_GELU.svg\" width=\"300px\" height=\"300px\"/>\n",
    "\n",
    "    - Derivative\n",
    "    $$\n",
    "    g'(z) = \n",
    "        \\begin{equation}\n",
    "            \\begin{cases}\n",
    "            0 & z < 0\\\\\n",
    "            1 & z \\ge 0\n",
    "            \\end{cases}\n",
    "        \\end{equation}\n",
    "    $$\n",
    "    \n",
    "<br><br>\n",
    "- leaky ReLU\n",
    "$$\n",
    "    a = max(0.01z, z)\n",
    "$$\n",
    "\n",
    "    - Derivative\n",
    "    \n",
    "    $$\n",
    "    g'(z) = \n",
    "        \\begin{equation}\n",
    "            \\begin{cases}\n",
    "            0.01 & z < 0\\\\\n",
    "            1 & z \\ge 0\n",
    "            \\end{cases}\n",
    "        \\end{equation}\n",
    "    $$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d445d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141d79f",
   "metadata": {},
   "source": [
    "## Implement L-Layered Neural Network functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0736d04",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e042caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        layer_dims: A list that contains the size of each layer\n",
    "        \n",
    "    returns:\n",
    "        dict: parameters for each layer\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1, L):\n",
    "        # This uses He initialization\n",
    "        params['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * np.sqrt(2 / layer_dims[l - 1])\n",
    "        params['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639e330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 :\n",
      "[[ 0.95437524 -1.03689608 -0.52241613]\n",
      " [ 0.76718099 -0.23603649  0.57884634]\n",
      " [ 0.08784132 -0.3429286   0.86768187]\n",
      " [ 0.38194731 -0.23133162  0.11412594]\n",
      " [ 1.10340849  0.22005801 -1.41533328]]\n",
      "b1 :\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 :\n",
      "[[-0.89776919  0.42377933 -0.65455811  0.16800102 -0.30302338]\n",
      " [-0.09777912  0.08127158 -1.42242477 -0.86892138 -0.61769557]\n",
      " [ 0.03500486  0.54639927  0.44264007 -0.7665579   0.29461592]\n",
      " [ 1.05038235  0.57500929 -0.3761933  -0.35245863 -0.73542231]]\n",
      "b2 :\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W3 :\n",
      "[[-2.00593744  0.47078282 -0.32507904 -0.56571994]]\n",
      "b3 :\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "# Test function\n",
    "params = initialize_parameters_deep([3, 5, 4, 1])\n",
    "for k, v in params.items():\n",
    "    print(k, \":\")\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428b907",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31941956",
   "metadata": {},
   "source": [
    "#### Linear forward\n",
    "Here we need to calculate $Z^{[l]} = W^{[l]}.A^{[l-1]} + b^{[l]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4871a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        A: activations from previous layer or inputs, shape=(size of l-1, m)\n",
    "        W: weights from layer l, shape=(size of layer l, size of layer l-1)\n",
    "        b: intercepts from layer l, shape(size of layer l, 1)\n",
    "        \n",
    "    returns:\n",
    "        Z: forward calculation\n",
    "        cache: The same arguments useful for backward propagation\n",
    "    \"\"\"\n",
    "    Z = np.dot(W, A) + b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7834cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.49354284  1.53142993  1.32485351  0.73463548]\n",
      " [-1.12434412  0.40720022  0.22403211  0.08417937]\n",
      " [-1.05949991 -0.44696833  0.31527115  0.20656968]\n",
      " [-0.43719629  0.34834004  0.26984766  0.13750739]\n",
      " [ 0.85115179  2.03889131 -0.09418118 -0.18362966]]\n",
      "[[-0.58478069  0.99332666  0.00691863 -0.08345636]\n",
      " [ 0.43625185 -0.21053868 -1.21259724 -0.75848054]\n",
      " [-0.98945109 -0.69890037 -0.11659903 -0.05325001]]\n",
      "[[ 0.95437524 -1.03689608 -0.52241613]\n",
      " [ 0.76718099 -0.23603649  0.57884634]\n",
      " [ 0.08784132 -0.3429286   0.86768187]\n",
      " [ 0.38194731 -0.23133162  0.11412594]\n",
      " [ 1.10340849  0.22005801 -1.41533328]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(3, 4)\n",
    "Y = np.array([[1, 0, 1, 0]])\n",
    "Z, cache = linear_forward(X, params['W1'], params['b1'])\n",
    "print(Z)\n",
    "print(cache[0])\n",
    "print(cache[1])\n",
    "print(cache[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e9c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        Z: a matrix calculated in \"linear_forward\" step\n",
    "        \n",
    "    returns:\n",
    "        A: activation function of sigmoid(Z)\n",
    "        cache: The same arguments useful for backward propagation\n",
    "    \"\"\"\n",
    "    cache = Z\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7763be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        Z: a matrix calculated in \"linear_forward\" step\n",
    "        \n",
    "    returns:\n",
    "        A: activation function of relu(Z)\n",
    "        cache: The same arguments useful for backward propagation\n",
    "    \"\"\"\n",
    "    cache = Z\n",
    "    A = np.maximum(0, Z)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49a3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        A: activations from previous layer or inputs, shape=(size of l-1, m)\n",
    "        W: weights from layer l, shape=(size of layer l, size of layer l-1)\n",
    "        b: intercepts from layer l, shape(size of layer l, 1)\n",
    "        activation: A string that specifies what type of activiation function to use (sigmoid or ReLU)\n",
    "    \n",
    "    returns:\n",
    "        A: activation calculated\n",
    "        cache: to be used for backward propagation\n",
    "    \"\"\"\n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        A, activation_cache = relu(Z)\n",
    "    elif activation == 'sigmoid':\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    else:\n",
    "        A, activation_cache = Z, Z\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1272e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.53142993 1.32485351 0.73463548]\n",
      " [0.         0.40720022 0.22403211 0.08417937]\n",
      " [0.         0.         0.31527115 0.20656968]\n",
      " [0.         0.34834004 0.26984766 0.13750739]\n",
      " [0.85115179 2.03889131 0.         0.        ]]\n",
      "(array([[-0.58478069,  0.99332666,  0.00691863, -0.08345636],\n",
      "       [ 0.43625185, -0.21053868, -1.21259724, -0.75848054],\n",
      "       [-0.98945109, -0.69890037, -0.11659903, -0.05325001]]), array([[ 0.95437524, -1.03689608, -0.52241613],\n",
      "       [ 0.76718099, -0.23603649,  0.57884634],\n",
      "       [ 0.08784132, -0.3429286 ,  0.86768187],\n",
      "       [ 0.38194731, -0.23133162,  0.11412594],\n",
      "       [ 1.10340849,  0.22005801, -1.41533328]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]))\n",
      "[[-0.49354284  1.53142993  1.32485351  0.73463548]\n",
      " [-1.12434412  0.40720022  0.22403211  0.08417937]\n",
      " [-1.05949991 -0.44696833  0.31527115  0.20656968]\n",
      " [-0.43719629  0.34834004  0.26984766  0.13750739]\n",
      " [ 0.85115179  2.03889131 -0.09418118 -0.18362966]]\n"
     ]
    }
   ],
   "source": [
    "A, cache = linear_activation_forward(X, params[\"W1\"], params[\"b1\"], activation='relu')\n",
    "print(A)\n",
    "print(cache[0])\n",
    "print(cache[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7a161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters=None, keep_prob=1.):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        X: numpy array, shape=(input size, input examples i.e m)\n",
    "        parameters: output of initialize_parameters_deep\n",
    "        keep_prob: the probability of which each perceptron is kept\n",
    "        \n",
    "    returns:\n",
    "        AL: activation value from the output layer\n",
    "        caches: Caches from calling Linear activation forward, the size is L since there are L layers\n",
    "    \"\"\"\n",
    "    caches = []\n",
    "    L = len(parameters) // 2\n",
    "    A_prev = X\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        Wl = parameters['W' + str(l)]\n",
    "        bl = parameters['b' + str(l)]\n",
    "        A, cache = linear_activation_forward(A_prev, Wl, bl, 'relu')\n",
    "        caches.append(cache)\n",
    "        \n",
    "        # Regularization : Drop out\n",
    "        D = np.random.rand(A.shape[0], A.shape[1])\n",
    "        D = (D <= keep_prob).astype(int)\n",
    "        A = A * D\n",
    "        A /= keep_prob\n",
    "        \n",
    "        A_prev = A\n",
    "        \n",
    "    WL = parameters['W' + str(L)]\n",
    "    bL = parameters['b' + str(L)]\n",
    "    AL, cache = linear_activation_forward(A_prev, WL, bL, 'sigmoid')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f8aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47963184 0.41995225 0.31599848 0.39859812]]\n",
      "\n",
      "\n",
      "[((array([[-0.58478069,  0.99332666,  0.00691863, -0.08345636],\n",
      "       [ 0.43625185, -0.21053868, -1.21259724, -0.75848054],\n",
      "       [-0.98945109, -0.69890037, -0.11659903, -0.05325001]]), array([[ 0.95437524, -1.03689608, -0.52241613],\n",
      "       [ 0.76718099, -0.23603649,  0.57884634],\n",
      "       [ 0.08784132, -0.3429286 ,  0.86768187],\n",
      "       [ 0.38194731, -0.23133162,  0.11412594],\n",
      "       [ 1.10340849,  0.22005801, -1.41533328]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])), array([[-0.49354284,  1.53142993,  1.32485351,  0.73463548],\n",
      "       [-1.12434412,  0.40720022,  0.22403211,  0.08417937],\n",
      "       [-1.05949991, -0.44696833,  0.31527115,  0.20656968],\n",
      "       [-0.43719629,  0.34834004,  0.26984766,  0.13750739],\n",
      "       [ 0.85115179,  2.03889131, -0.09418118, -0.18362966]])), ((array([[0.        , 1.53142993, 1.32485351, 0.73463548],\n",
      "       [0.        , 0.40720022, 0.22403211, 0.08417937],\n",
      "       [0.        , 0.        , 0.31527115, 0.20656968],\n",
      "       [0.        , 0.34834004, 0.26984766, 0.13750739],\n",
      "       [0.85115179, 2.03889131, 0.        , 0.        ]]), array([[-0.89776919,  0.42377933, -0.65455811,  0.16800102, -0.30302338],\n",
      "       [-0.09777912,  0.08127158, -1.42242477, -0.86892138, -0.61769557],\n",
      "       [ 0.03500486,  0.54639927,  0.44264007, -0.7665579 ,  0.29461592],\n",
      "       [ 1.05038235,  0.57500929, -0.3761933 , -0.35245863, -0.73542231]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])), array([[-0.25791889, -1.76161782, -1.25550108, -0.7359701 ],\n",
      "       [-0.52575268, -1.6787423 , -0.79426146, -0.47830356],\n",
      "       [ 0.25076286,  0.60976841,  0.10148508,  0.05774   ],\n",
      "       [-0.62595601,  0.22050927,  1.30671025,  0.69387626]])), ((array([[0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [0.25076286, 0.60976841, 0.10148508, 0.05774   ],\n",
      "       [0.        , 0.22050927, 1.30671025, 0.69387626]]), array([[-2.00593744,  0.47078282, -0.32507904, -0.56571994]]), array([[0.]])), array([[-0.08151775, -0.32296942, -0.77222271, -0.4113097 ]]))]\n"
     ]
    }
   ],
   "source": [
    "AL, caches = L_model_forward(X, params)\n",
    "print(AL)\n",
    "print('\\n')\n",
    "print(caches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c05f2",
   "metadata": {},
   "source": [
    "#### Compute Cost\n",
    "Cost for sigmoid function is defined as\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right))$$\n",
    "$$J_{regularized} = \\small \\underbrace{-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(}\\small y^{(i)}\\log\\left(a^{[L](i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right) \\large{)} }_\\text{cross-entropy cost} + \\underbrace{\\frac{1}{m} \\frac{\\lambda}{2} \\sum\\limits_l\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2} }_\\text{L2 regularization cost}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a4b0545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frobenius_norm(parameters):\n",
    "    L = len(parameters) // 2\n",
    "    summation = 0\n",
    "    for l in range(1, L + 1):\n",
    "        W_kj = parameters['W' + str(l)]\n",
    "        summation += np.sum(np.square(W_kj))\n",
    "    return np.sqrt(summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf815bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivative_frobenius_norm(parameter, parameters):\n",
    "    l2norm = compute_frobenius_norm(parameters)\n",
    "    return parameter / l2norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53656f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y, parameters=None, lambda_=0.):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        AL: nparray; the output of the neural network\n",
    "        Y: array of labels\n",
    "        parameters: dictionary of the parameters containing Ws and bs to calculate ||W||F\n",
    "        lambda_: is a scalar as regularization parameter\n",
    "    returns:\n",
    "        decimal number specifing the cost\n",
    "    \"\"\"\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    m = Y.shape[1]\n",
    "    cost = np.multiply(-Y, np.log(AL)) - np.multiply(1 - Y, np.log(1 - AL))\n",
    "    cost = np.sum(cost, axis=1) / (m)\n",
    "    \n",
    "    reg_cost = (lambda_ * compute_frobenius_norm(parameters) ** 2) / (2 * m)\n",
    "    cost += reg_cost\n",
    "        \n",
    "    return np.squeeze(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b6a932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.7375215)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "compute_cost(AL, Y, params, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9670b8",
   "metadata": {},
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7aec0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        dA: post-activation gradient, of any shape\n",
    "        cache: it is \"Z\" that we stored to use later in back prop\n",
    "    \n",
    "    returns:\n",
    "        derivative of loss function with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    dZ = dA * s * (1 - s)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "854f7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        dA: post-activation gradient, of any shape\n",
    "        cache: it is \"Z\" that we stored to use later in back prop\n",
    "    \n",
    "    returns:\n",
    "        derivative of loss function with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a77b6",
   "metadata": {},
   "source": [
    "Let's say we have dZ, now we are to find:\n",
    "$$ dW^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T}$$\n",
    "$$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}$$\n",
    "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]}$$\n",
    "And for regularization update we have\n",
    "$$\\frac{d}{dW} ( \\frac{1}{2}\\frac{\\lambda}{m}  W^2) = \\frac{\\lambda}{m} W$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a5b1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        dZ: gradient of the cost with respect to the linear output i.e Z\n",
    "        cache: the tupe (A_prev, W, b)\n",
    "    \n",
    "    returns:\n",
    "        dW: gradient of the cost with respect to the weights i.e W\n",
    "        db: gradient of the cost with respect to the intercepts i.e b\n",
    "        dA_prev: gradient of the cost with respect to the activation function in the previous layer\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = np.matmul(dZ, A_prev.T) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    dA_prev = np.matmul(W.T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cdf1f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        dA: post-activation gradient for current layer l\n",
    "        cache: tuple contaning (linear_cache, activation_cache)\n",
    "        activation: activation function go to be used in this layer\n",
    "        \n",
    "    returns:\n",
    "        dW: gradient of the cost with respect to the weights i.e W\n",
    "        db: gradient of the cost with respect to the intercepts i.e b\n",
    "        dA_prev: gradient of the cost with respect to the activation function in the previous layer\n",
    "    \"\"\"\n",
    "    \n",
    "    (linear_cache, activation_cache) = cache\n",
    "    if activation == 'relu':\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "    elif activation == 'sigmoid':\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "    \n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55c96dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches, parameters, lambda_=0, keep_prob=1.):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        AL: predicted outputs from the neural network\n",
    "        Y: correct values\n",
    "        caches: cached values in each step of linear forward and linear activation forward\n",
    "        parameters: dictionary of the parameters containing Ws and bs to calculate ||W||F\n",
    "        lambda_: is a scalar as regularization parameter\n",
    "    returns:\n",
    "        gradients that are --> dA_prev, dW, db for each layer\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    L = len(caches)\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    current_cache = caches[L - 1]\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    dA_prev, dW, db = linear_activation_backward(dAL, current_cache, 'sigmoid')\n",
    "    grads['dW' + str(L)] = dW\n",
    "    grads['db' + str(L)] = db\n",
    "    grads['dA' + str(L - 1)] = dA_prev\n",
    "    \n",
    "    for l in reversed(range(L - 1)):\n",
    "        current_cache = caches[l] # caches[l] means, caches from layer l+1\n",
    "        dA_prev, dW, db = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, 'relu')\n",
    "        grads['dW' + str(l + 1)] = dW\n",
    "        grads['db' + str(l + 1)] = db\n",
    "        grads['dA' + str(l)] = dA_prev\n",
    "        \n",
    "    \n",
    "    # This does not calculate d||W||F/dW it calculates d||W||F^2/dW\n",
    "    for l in range(1, L + 1):\n",
    "        grads['dW' + str(l)] += lambda_/m * parameters['W' + str(l)]\n",
    "        \n",
    "        \n",
    "    # Regularization : Dropout\n",
    "    for l in range(1, L):\n",
    "        grad_A = grads['dA' + str(l)]\n",
    "        D = np.random.rand(grad_A.shape[0], grad_A.shape[1])\n",
    "        D = (D <= keep_prob).astype(int)\n",
    "        grad_A = grad_A * D\n",
    "        grads['dA' + str(l)] = grad_A\n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80dde1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dW3': array([[-5.01484361e-04,  1.17695705e-04,  1.97146590e-02,\n",
       "         -1.31294093e-01]]),\n",
       " 'db3': array([[-0.09645483]]),\n",
       " 'dA2': array([[ 1.04382598, -0.84239794,  1.37206425, -0.7995629 ],\n",
       "        [-0.24498039,  0.1977063 , -0.32201616,  0.18765315],\n",
       "        [ 0.16916078, -0.13651768,  0.22235456, -0.1295759 ],\n",
       "        [ 0.29438264, -0.23757536,  0.3869533 , -0.2254949 ]]),\n",
       " 'dW2': array([[-2.24442296e-04,  1.05944832e-04, -1.63639527e-04,\n",
       "          4.20002542e-05, -7.57558439e-05],\n",
       "        [-2.44447804e-05,  2.03178947e-05, -3.55606192e-04,\n",
       "         -2.17230345e-04, -1.54423891e-04],\n",
       "        [-2.40902081e-03, -4.03417106e-03,  1.09445413e-02,\n",
       "         -1.53422887e-03, -3.35171457e-02],\n",
       "        [-3.94494060e-03, -7.11444621e-03,  1.87596513e-02,\n",
       "         -2.42456053e-03, -1.21281440e-01]]),\n",
       " 'db2': array([[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.03135544],\n",
       "        [-0.01902924]]),\n",
       " 'dA1': array([[ 0.00592145, -0.25432375,  0.4142324 , -0.24139165],\n",
       "        [ 0.09242933, -0.2112012 ,  0.34399611, -0.20046184],\n",
       "        [ 0.07487734,  0.02894607, -0.0471462 ,  0.02747419],\n",
       "        [-0.12967154,  0.18838419, -0.30683267,  0.17880505],\n",
       "        [ 0.04983746,  0.13449794, -0.21906489,  0.12765886]]),\n",
       " 'dW1': array([[-0.05716515, -0.06667453,  0.03544489],\n",
       "        [-0.0474787 , -0.05521308,  0.02968811],\n",
       "        [-0.00063281,  0.00899695,  0.00122547],\n",
       "        [ 0.04261593,  0.0491377 , -0.02632316],\n",
       "        [ 0.02638995, -0.00158882, -0.03618193]]),\n",
       " 'db1': array([[-0.02037075],\n",
       "        [-0.01691673],\n",
       "        [-0.004918  ],\n",
       "        [ 0.01508914],\n",
       "        [ 0.04608385]]),\n",
       " 'dA0': array([[ 0.05499108, -0.18439083,  0.53790512, -0.31346125],\n",
       "        [ 0.01096713,  0.29957661, -0.42356371,  0.24682942],\n",
       "        [-0.07053661, -0.1582501 , -0.09320627,  0.05431544]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "grads = L_model_backward(AL, Y, caches, params, 0.001)\n",
    "grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f7a8a",
   "metadata": {},
   "source": [
    "### Update Parameters\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93327cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    arguments\n",
    "        params: is the parameters that we initialized\n",
    "        grads: gradients that are calculated in \"L_model_backward\"\n",
    "        learning_rate: a decimal illustrating how much of the gradient should effect params\n",
    "    \n",
    "    return:\n",
    "        updated parameters\n",
    "    \"\"\"\n",
    "    L = len(params) // 2\n",
    "    parameters = params.copy()\n",
    "    \n",
    "    for l in range(1, L + 1):\n",
    "        parameters['W' + str(l)] = params['W' + str(l)] - learning_rate * grads['dW' + str(l)]\n",
    "        parameters['b' + str(l)] = params['b' + str(l)] - learning_rate * grads['db' + str(l)]\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a54e8247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.95494689, -1.03622934, -0.52277058],\n",
       "        [ 0.76765577, -0.23548435,  0.57854946],\n",
       "        [ 0.08784765, -0.34301856,  0.86766962],\n",
       "        [ 0.38152115, -0.231823  ,  0.11438917],\n",
       "        [ 1.10314459,  0.2200739 , -1.41497146]]),\n",
       " 'b1': array([[ 2.03707497e-04],\n",
       "        [ 1.69167322e-04],\n",
       "        [ 4.91800284e-05],\n",
       "        [-1.50891422e-04],\n",
       "        [-4.60838497e-04]]),\n",
       " 'W2': array([[-0.89776694,  0.42377827, -0.65455647,  0.1680006 , -0.30302262],\n",
       "        [-0.09777888,  0.08127138, -1.42242121, -0.86891921, -0.61769402],\n",
       "        [ 0.03502895,  0.54643961,  0.44253063, -0.76654256,  0.29495109],\n",
       "        [ 1.0504218 ,  0.57508043, -0.3763809 , -0.35243439, -0.73420949]]),\n",
       " 'b2': array([[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.00031355],\n",
       "        [ 0.00019029]]),\n",
       " 'W3': array([[-2.00593243,  0.47078164, -0.32527619, -0.564407  ]]),\n",
       " 'b3': array([[0.00096455]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "update_parameters(params, grads, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2712bae",
   "metadata": {},
   "source": [
    "## Gradient Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9102e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_dictionary(vector, parameters):\n",
    "    \"\"\"\n",
    "    Convert a vector into a dictionary of parameters\n",
    "    Arguments:\n",
    "    vector -- The vector to convert\n",
    "    parameters -- A dictionary of parameters, containing the shapes of the parameters\n",
    "    \n",
    "    Returns:\n",
    "    dictionary -- A dictionary of parameters from the vector\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2\n",
    "    index = 0\n",
    "    for l in range(1, L + 1):\n",
    "        shape = parameters['W' + str(l)].shape\n",
    "        size = np.prod(shape)\n",
    "        parameters['W' + str(l)] = np.reshape(vector[index:index + size], shape)\n",
    "        index += size\n",
    "        \n",
    "        shape = parameters['b' + str(l)].shape\n",
    "        size = np.prod(shape)\n",
    "        parameters['b' + str(l)] = np.reshape(vector[index:index + size], shape)\n",
    "        index += size\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ea889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_vector(params):\n",
    "    \"\"\"Flatten dictionary to vector.\"\"\"\n",
    "    L = len(params) // 2\n",
    "    vec = np.array([])\n",
    "    for l in range(1, L + 1):\n",
    "        vec = np.concatenate((vec, params['W' + str(l)].flatten()))\n",
    "        vec = np.concatenate((vec, params['b' + str(l)].flatten()))\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ce78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grads_to_vec(grads, L):\n",
    "    \"\"\"Flatten gradients to vector.\"\"\"\n",
    "    vec = np.array([])\n",
    "    for l in range(1, L + 1):\n",
    "        vec = np.concatenate((vec, grads['dW' + str(l)].flatten()))\n",
    "        vec = np.concatenate((vec, grads['db' + str(l)].flatten()))\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74df7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(X, Y, parameters, grads, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Implement gradient check\n",
    "    \n",
    "    Arguments:\n",
    "    X -- Input data, shape (input size, number of examples)\n",
    "    Y -- True labels, shape (output size, number of examples)\n",
    "    parameters -- Output of initialize_parameters_deep\n",
    "    grads -- Output of backward_propagation\n",
    "    epsilon -- Small epsilon value for numeric approximation of gradient\n",
    "    \n",
    "    Returns:\n",
    "    difference -- Difference between numeric gradient and backprop gradient\n",
    "    \"\"\"\n",
    "    parameters_values = dict_to_vector(parameters)\n",
    "    num_parameters = parameters_values.shape[0]\n",
    "    grad = grads_to_vec(grads, len(parameters) // 2).reshape(-1, 1)\n",
    "    J_plus = np.zeros((num_parameters, 1))\n",
    "    J_minus = np.zeros((num_parameters, 1))\n",
    "    gradapprox = np.zeros((num_parameters, 1))\n",
    "    \n",
    "    for i in range(num_parameters):\n",
    "        thetaplus = np.copy(parameters_values)                                      \n",
    "        thetaplus[i] = thetaplus[i] + epsilon   \n",
    "        AL, _ = L_model_forward(X, vector_to_dictionary(thetaplus, parameters))                 \n",
    "        J_plus[i] = compute_cost(AL, Y, parameters)     \n",
    "        \n",
    "        thetaminus = np.copy(parameters_values)                                     \n",
    "        thetaminus[i] = thetaminus[i] - epsilon                               \n",
    "        AL, _ = L_model_forward(X, vector_to_dictionary(thetaminus, parameters))                \n",
    "        J_minus[i] = compute_cost(AL, Y, parameters)                                            \n",
    "        \n",
    "        gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)                    \n",
    "    \n",
    "    numerator = np.linalg.norm(grad - gradapprox)                                   \n",
    "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                \n",
    "    difference = numerator / denominator   \n",
    "    \n",
    "    if difference > 2 * epsilon:\n",
    "        print(\"There is a mistake in the backward propagation! difference = \" + str(difference))\n",
    "    else:\n",
    "        print(\"Your backward propagation works perfectly fine! difference = \" + str(difference))\n",
    "    \n",
    "    return difference, gradapprox, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b3714",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f942585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=400, n_features=2, n_informative=2, n_redundant=0, n_classes=2, class_sep=0.7,\n",
    "                           scale=[5, 5], n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "190ebc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], alpha=0.5);\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], alpha=0.5);\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('$x_1$');\n",
    "ax.set_ylabel('$x_2$');\n",
    "#ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c980bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.4)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_cv, y_cv, test_size=0.5)\n",
    "# Normalization\n",
    "norm = Normalizer().fit(X_train)\n",
    "Xn_train = norm.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e28ae414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(Xn_train[y_train == 1, 0], Xn_train[y_train == 1, 1], alpha=0.5);\n",
    "plt.scatter(Xn_train[y_train == 0, 0], Xn_train[y_train == 0, 1], alpha=0.5);\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('$x_1$');\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "161d20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, iterations=100, learning_rate=0.01, lambda_=0, keep_prob=1, verbos=True, debug_mode=False):\n",
    "    hist = []\n",
    "    parameters = initialize_parameters_deep([2, 4, 1])\n",
    "    \n",
    "    for i in range(1, iterations + 1):\n",
    "        AL, caches = L_model_forward(X, parameters, keep_prob)\n",
    "        grads = L_model_backward(AL, y, caches, parameters, lambda_)\n",
    "        \n",
    "        if debug_mode:\n",
    "            gradient_check(X, y, parameters, grads) # Do gradient check\n",
    "            \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        cost = compute_cost(AL, y, parameters, lambda_)\n",
    "        hist.append(cost)\n",
    "        if verbos and i % 100 == 0:\n",
    "            print(f'Iteration {i} : cost is {cost}')\n",
    "        \n",
    "    return parameters, grads, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "705b10f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 : cost is 0.7566008750095276\n",
      "Iteration 200 : cost is 0.6361147612100877\n",
      "Iteration 300 : cost is 0.5561987747627917\n",
      "Iteration 400 : cost is 0.4897932674115071\n",
      "Iteration 500 : cost is 0.43206772217368794\n",
      "Iteration 600 : cost is 0.3826546004938067\n",
      "Iteration 700 : cost is 0.34062520493086307\n",
      "Iteration 800 : cost is 0.30566695792661175\n",
      "Iteration 900 : cost is 0.2772453301188208\n",
      "Iteration 1000 : cost is 0.254544378339997\n",
      "Iteration 1100 : cost is 0.2365017783012573\n",
      "Iteration 1200 : cost is 0.2220578475489177\n",
      "Iteration 1300 : cost is 0.2100306293435139\n",
      "Iteration 1400 : cost is 0.2004131117876339\n",
      "Iteration 1500 : cost is 0.19307666220529268\n",
      "Iteration 1600 : cost is 0.18701460001221376\n",
      "Iteration 1700 : cost is 0.18257044871138634\n",
      "Iteration 1800 : cost is 0.1793455479101622\n",
      "Iteration 1900 : cost is 0.17692007226143366\n",
      "Iteration 2000 : cost is 0.17506858913467924\n",
      "Iteration 2100 : cost is 0.17369444804924\n",
      "Iteration 2200 : cost is 0.17262376994497158\n",
      "Iteration 2300 : cost is 0.17178541734529365\n",
      "Iteration 2400 : cost is 0.17111940638242415\n",
      "Iteration 2500 : cost is 0.1705686664359172\n",
      "Iteration 2600 : cost is 0.17010573882120336\n",
      "Iteration 2700 : cost is 0.16971081166127036\n",
      "Iteration 2800 : cost is 0.16937467910124504\n",
      "Iteration 2900 : cost is 0.16910960099384773\n",
      "Iteration 3000 : cost is 0.16888443698388833\n",
      "Iteration 3100 : cost is 0.16869420300956364\n",
      "Iteration 3200 : cost is 0.16852835718856884\n",
      "Iteration 3300 : cost is 0.16838244559142704\n",
      "Iteration 3400 : cost is 0.16824987529836283\n",
      "Iteration 3500 : cost is 0.1681345734068423\n",
      "Iteration 3600 : cost is 0.16802878687470205\n",
      "Iteration 3700 : cost is 0.1679295551598662\n",
      "Iteration 3800 : cost is 0.1678357256816783\n",
      "Iteration 3900 : cost is 0.16774638060992775\n",
      "Iteration 4000 : cost is 0.16766078588754535\n",
      "Iteration 4100 : cost is 0.16757835191334805\n",
      "Iteration 4200 : cost is 0.1674986030780445\n",
      "Iteration 4300 : cost is 0.1674234124852293\n",
      "Iteration 4400 : cost is 0.16735350778548655\n",
      "Iteration 4500 : cost is 0.16728550432348183\n",
      "Iteration 4600 : cost is 0.1672191150402787\n",
      "Iteration 4700 : cost is 0.1671543883302893\n",
      "Iteration 4800 : cost is 0.16709101480566713\n",
      "Iteration 4900 : cost is 0.16702899274476793\n",
      "Iteration 5000 : cost is 0.16696807221307872\n",
      "Iteration 5100 : cost is 0.16690809661912082\n",
      "Iteration 5200 : cost is 0.16684891473540528\n",
      "Iteration 5300 : cost is 0.16679081382472116\n",
      "Iteration 5400 : cost is 0.1667334098010541\n",
      "Iteration 5500 : cost is 0.16667650830096614\n",
      "Iteration 5600 : cost is 0.16662006627952977\n",
      "Iteration 5700 : cost is 0.1665640475176175\n",
      "Iteration 5800 : cost is 0.16650842133809987\n",
      "Iteration 5900 : cost is 0.16645316158057172\n",
      "Iteration 6000 : cost is 0.16639824577888204\n",
      "Iteration 6100 : cost is 0.16634365449883468\n",
      "Iteration 6200 : cost is 0.16628937080311845\n",
      "Iteration 6300 : cost is 0.16623577468469108\n",
      "Iteration 6400 : cost is 0.16618323002268778\n",
      "Iteration 6500 : cost is 0.16613101387244902\n",
      "Iteration 6600 : cost is 0.16607910406180168\n",
      "Iteration 6700 : cost is 0.16602747813712024\n",
      "Iteration 6800 : cost is 0.16597610322504688\n",
      "Iteration 6900 : cost is 0.1659249679118343\n",
      "Iteration 7000 : cost is 0.1658740606139105\n",
      "Iteration 7100 : cost is 0.1658233603143944\n",
      "Iteration 7200 : cost is 0.16577285721135276\n",
      "Iteration 7300 : cost is 0.16572257519408257\n",
      "Iteration 7400 : cost is 0.16567262415981615\n",
      "Iteration 7500 : cost is 0.16562285146939135\n",
      "Iteration 7600 : cost is 0.16557344625038656\n",
      "Iteration 7700 : cost is 0.1655242593856139\n",
      "Iteration 7800 : cost is 0.1654754115376396\n",
      "Iteration 7900 : cost is 0.16542677118763577\n",
      "Iteration 8000 : cost is 0.16537868280488244\n",
      "Iteration 8100 : cost is 0.16533090603464462\n",
      "Iteration 8200 : cost is 0.16528321756566272\n",
      "Iteration 8300 : cost is 0.165235612221391\n",
      "Iteration 8400 : cost is 0.16518808533702364\n",
      "Iteration 8500 : cost is 0.16514063265917603\n",
      "Iteration 8600 : cost is 0.1650932513004658\n",
      "Iteration 8700 : cost is 0.16504608296853843\n",
      "Iteration 8800 : cost is 0.16499908429555019\n",
      "Iteration 8900 : cost is 0.16495209866719057\n",
      "Iteration 9000 : cost is 0.1649050353661932\n",
      "Iteration 9100 : cost is 0.16485801484243373\n",
      "Iteration 9200 : cost is 0.16481103433130456\n",
      "Iteration 9300 : cost is 0.16476409127820982\n",
      "Iteration 9400 : cost is 0.1647175187214981\n",
      "Iteration 9500 : cost is 0.16467185490932587\n",
      "Iteration 9600 : cost is 0.16462629104385298\n",
      "Iteration 9700 : cost is 0.16458146348152933\n",
      "Iteration 9800 : cost is 0.16453667700684882\n",
      "Iteration 9900 : cost is 0.16449192256925776\n",
      "Iteration 10000 : cost is 0.16444719356482013\n"
     ]
    }
   ],
   "source": [
    "params, grads, hist = model(Xn_train.T, y_train, iterations=10000, learning_rate=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "17468a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    y_hat, _ = L_model_forward(X, parameters)\n",
    "    y_hat[y_hat > 0.5] = 1\n",
    "    y_hat[y_hat <= 0.5] = 0\n",
    "    return (y == y_hat).sum() / y_hat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5b790880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9541666666666667"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(Xn_train.T, y_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6b228ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(norm.transform(X_cv).T, y_cv, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "aa528ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(norm.transform(X_test).T, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f81e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
